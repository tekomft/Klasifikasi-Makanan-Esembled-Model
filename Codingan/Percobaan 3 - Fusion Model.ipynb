{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2, Xception\n",
    "from tensorflow.keras.layers import Concatenate, Dense, GlobalAveragePooling2D, Add, Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Dictionary\n",
    "dic = {0: 'Buras', 1: 'Dangkot', 2: 'Gogos', 3: 'Kapurung', 4: 'Sokko', 5: 'Sop Konro'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess image function\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img = image.img_to_array(img) / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Predict function\n",
    "def ensemble_predict(img_path, mobilenetv2_model, xception_model):\n",
    "    img = preprocess_image(img_path)\n",
    "    mobilenetv2_pred = mobilenetv2_model.predict(img)\n",
    "    xception_pred = xception_model.predict(img)\n",
    "    final_pred = (mobilenetv2_pred + xception_pred) / 2.0  # Average probabilities\n",
    "#    return np.argmax(final_pred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load models for ensemble\n",
    "mobilenetv2_model = load_model(\"D:/Kuliah Semester 6/Jurnal/Materi/CNN/mobilenetv2_custom_model.h5\")\n",
    "xception_model = load_model(r\"D:\\Kuliah Semester 6\\Jurnal\\Materi\\CNN\\Codingan\\model\\Bugis_Xception-Makanan-Bugis-Exception-86.07.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict function for ensemble\n",
    "def predict_label_ensemble(img_path):\n",
    "    pred = ensemble_predict(img_path, mobilenetv2_model, xception_model)\n",
    "    return dic[pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Fusion Model\n",
    "def create_feature_fusion_model():\n",
    "    mobilenetv2_base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    xception_base = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    mobilenetv2_features = GlobalAveragePooling2D()(mobilenetv2_base.output)\n",
    "    xception_features = GlobalAveragePooling2D()(xception_base.output)\n",
    "    combined_features = Concatenate()([mobilenetv2_features, xception_features])\n",
    "\n",
    "    output = Dense(6, activation='softmax')(combined_features)\n",
    "\n",
    "    model = Model(inputs=[mobilenetv2_base.input, xception_base.input], outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Architecture Model\n",
    "#def create_hybrid_model():\n",
    "#    mobilenetv2_base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "#    xception_base = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "#    mobilenetv2_features = GlobalAveragePooling2D()(mobilenetv2_base.output)\n",
    "#    xception_features = GlobalAveragePooling2D()(xception_base.output)\n",
    "\n",
    "#    combined_features = Add()([mobilenetv2_features, xception_features])\n",
    "#    output = Dense(6, activation='softmax')(combined_features)\n",
    "\n",
    "#    model = Model(inputs=[mobilenetv2_base.input, xception_base.input], outputs=output)\n",
    "#    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning Combination Model\n",
    "#def create_transfer_learning_model():\n",
    "#    mobilenetv2_base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "#    xception_base = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "#    for layer in mobilenetv2_base.layers:\n",
    "#        layer.trainable = False\n",
    "#    for layer in xception_base.layers:\n",
    "#        layer.trainable = False\n",
    "\n",
    "#    mobilenetv2_features = GlobalAveragePooling2D()(mobilenetv2_base.output)\n",
    "#    xception_features = GlobalAveragePooling2D()(xception_base.output)\n",
    "#    combined_features = Concatenate()([mobilenetv2_features, xception_features])\n",
    "\n",
    "#    output = Dense(6, activation='softmax')(combined_features)\n",
    "#    model = Model(inputs=[mobilenetv2_base.input, xception_base.input], outputs=output)\n",
    "\n",
    "#    for layer in mobilenetv2_base.layers[-20:]:\n",
    "#        layer.trainable = True\n",
    "#    for layer in xception_base.layers[-20:]:\n",
    "#        layer.trainable = True\n",
    "\n",
    "#    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Fusion Model\n",
    "feature_fusion_model = create_feature_fusion_model()\n",
    "feature_fusion_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#feature_fusion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Model\n",
    "# hybrid_model = create_hybrid_model()\n",
    "# hybrid_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# hybrid_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning Model\n",
    "# transfer_learning_model = create_transfer_learning_model()\n",
    "# transfer_learning_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# transfer_learning_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"E:/Dataset/BURAS.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# For ensemble model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpredict_label_ensemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m, in \u001b[0;36mpredict_label_ensemble\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_label_ensemble\u001b[39m(img_path):\n\u001b[0;32m      3\u001b[0m     pred \u001b[38;5;241m=\u001b[39m ensemble_predict(img_path, mobilenetv2_model, xception_model)\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dic[\u001b[43mpred\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# For ensemble model\n",
    "print(predict_label_ensemble(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# For feature fusion, hybrid, or transfer learning model prediction, use model.predict method after training\u001b[39;00m\n\u001b[0;32m      2\u001b[0m img \u001b[38;5;241m=\u001b[39m preprocess_image(img_path)\n\u001b[1;32m----> 3\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_feature_fusion_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(img)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(dic[np\u001b[38;5;241m.\u001b[39margmax(pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# For feature fusion, hybrid, or transfer learning model prediction, use model.predict method after training\n",
    "img = preprocess_image(img_path)\n",
    "pred = create_feature_fusion_model.predict(img)\n",
    "print(dic[np.argmax(pred, axis=-1)[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
